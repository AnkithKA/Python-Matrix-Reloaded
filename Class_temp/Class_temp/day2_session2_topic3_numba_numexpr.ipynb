{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 🔧 Loop Unrolling and JIT Compilation  \n",
        "## A Deep Dive into Accelerating CPU-bound Python Code with Numba and Numexpr\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# 🔁 Loop Unrolling in Python\n",
        "\n",
        "Loop unrolling is an optimization technique that reduces loop overhead by processing multiple elements per iteration.\n",
        "\n",
        "### ✅ Why Use It?\n",
        "- Reduces loop control overhead\n",
        "- Improves cache usage and instruction-level parallelism\n",
        "- Can speed up small arithmetic loops\n",
        "\n",
        "### ⚠️ When to Avoid It?\n",
        "- For large or complex loop bodies\n",
        "- If you're already using vectorized libraries like NumPy\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 Example: Normal vs. Unrolled Loop\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def normal_loop(x, y, out):\n",
        "    for i in range(len(x)):\n",
        "        out[i] = x[i] + y[i]\n",
        "\n",
        "def unrolled_loop(x, y, out):\n",
        "    # Process 4 items at a time\n",
        "    for i in range(0, len(x) - 3, 4):\n",
        "        out[i]     = x[i]     + y[i]\n",
        "        out[i + 1] = x[i + 1] + y[i + 1]\n",
        "        out[i + 2] = x[i + 2] + y[i + 2]\n",
        "        out[i + 3] = x[i + 3] + y[i + 3]\n",
        "    \n",
        "    # Handle remaining elements\n",
        "    for i in range(len(x) - (len(x) % 4), len(x)):\n",
        "        out[i] = x[i] + y[i]\n",
        "```\n",
        "\n",
        "### 📊 Benchmarking Loop Performance\n",
        "\n",
        "```python\n",
        "size = 10_000_000\n",
        "a = np.random.rand(size)\n",
        "b = np.random.rand(size)\n",
        "result_normal = np.zeros_like(a)\n",
        "result_unrolled = np.zeros_like(a)\n",
        "\n",
        "# Time normal loop\n",
        "start = time.time()\n",
        "normal_loop(a, b, result_normal)\n",
        "normal_time = time.time() - start\n",
        "print(f\"Normal loop time: {normal_time:.4f} seconds\")\n",
        "\n",
        "# Time unrolled loop\n",
        "start = time.time()\n",
        "unrolled_loop(a, b, result_unrolled)\n",
        "unrolled_time = time.time() - start\n",
        "print(f\"Unrolled loop time: {unrolled_time:.4f} seconds\")\n",
        "print(f\"Speedup: {normal_time / unrolled_time:.2f}x\")\n",
        "```\n",
        "\n",
        "> 💡 Sample Output:\n",
        "```\n",
        "Normal loop time: 1.2345 seconds\n",
        "Unrolled loop time: 0.8901 seconds\n",
        "Speedup: 1.39x\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 🚀 Just-In-Time (JIT) Compilation with Numba\n",
        "\n",
        "Numba compiles Python functions to machine code at runtime using LLVM — often achieving near-C speeds.\n",
        "\n",
        "## 🧩 How Numba Works:\n",
        "1. Decorate function with `@jit` or `@njit`\n",
        "2. Numba infers types and compiles optimized machine code\n",
        "3. Compiled code is cached for faster future calls\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 Example: JIT Speedup Using Numba\n",
        "\n",
        "```python\n",
        "from numba import jit, njit, prange, set_num_threads\n",
        "\n",
        "@njit  # Fastest mode: nopython=True\n",
        "def numba_loop(x, y):\n",
        "    result = np.empty_like(x)\n",
        "    for i in range(len(x)):\n",
        "        result[i] = x[i] + y[i]\n",
        "    return result\n",
        "\n",
        "@njit(parallel=True)\n",
        "def numba_parallel_loop(x, y):\n",
        "    result = np.empty_like(x)\n",
        "    for i in prange(len(x)):  # Parallelized loop\n",
        "        result[i] = x[i] + y[i]\n",
        "    return result\n",
        "```\n",
        "\n",
        "### 📈 Benchmarking Numba\n",
        "\n",
        "```python\n",
        "size = 10_000_000\n",
        "a = np.random.rand(size)\n",
        "b = np.random.rand(size)\n",
        "\n",
        "# Baseline: Pure Python loop\n",
        "start = time.time()\n",
        "normal_loop(a, b, result_normal)\n",
        "python_time = time.time() - start\n",
        "print(f\"Python loop time: {python_time:.4f} seconds\")\n",
        "\n",
        "# Numba nopython\n",
        "start = time.time()\n",
        "res_numba = numba_loop(a, b)\n",
        "numba_time = time.time() - start\n",
        "print(f\"Numba loop time: {numba_time:.4f} seconds\")\n",
        "print(f\"Numba speedup: {python_time / numba_time:.2f}x\")\n",
        "\n",
        "# Numba parallel\n",
        "start = time.time()\n",
        "res_numba_par = numba_parallel_loop(a, b)\n",
        "numba_par_time = time.time() - start\n",
        "print(f\"Numba parallel time: {numba_par_time:.4f} seconds\")\n",
        "print(f\"Numba parallel speedup: {python_time / numba_par_time:.2f}x\")\n",
        "```\n",
        "\n",
        "> 📌 You'll typically see:\n",
        "- **Numba**: 10–100x speedups over pure Python\n",
        "- **Parallel Numba**: Additional gains on multi-core CPUs\n",
        "\n",
        "---\n",
        "\n",
        "# 🧮 Vectorized Math Expression Optimization with Numexpr\n",
        "\n",
        "Numexpr evaluates array expressions efficiently using:\n",
        "- Virtual machine\n",
        "- Multi-threading\n",
        "- Memory-efficient execution\n",
        "\n",
        "## 🧪 Example: Evaluate Complex Formula\n",
        "\n",
        "```python\n",
        "import numexpr as ne\n",
        "\n",
        "def compute_with_numpy(x, y, z):\n",
        "    return np.exp(-(x - y)**2) / (1 + (x + y)**2)\n",
        "\n",
        "def compute_with_numexpr(x, y, z):\n",
        "    return ne.evaluate(\"exp(-(x - y)**2) / (1 + (x + y)**2)\")\n",
        "```\n",
        "\n",
        "### 📊 Benchmarking Numexpr vs NumPy\n",
        "\n",
        "```python\n",
        "size = 10_000_000\n",
        "x = np.random.rand(size)\n",
        "y = np.random.rand(size)\n",
        "z = np.random.rand(size)\n",
        "\n",
        "# With NumPy\n",
        "start = time.time()\n",
        "result_numpy = compute_with_numpy(x, y, z)\n",
        "numpy_time = time.time() - start\n",
        "print(f\"NumPy time: {numpy_time:.4f} seconds\")\n",
        "\n",
        "# With Numexpr\n",
        "start = time.time()\n",
        "result_numexpr = compute_with_numexpr(x, y, z)\n",
        "numexpr_time = time.time() - start\n",
        "print(f\"Numexpr time: {numexpr_time:.4f} seconds\")\n",
        "print(f\"Numexpr speedup: {numpy_time / numexpr_time:.2f}x\")\n",
        "```\n",
        "\n",
        "> 🚀 Numexpr can be **2–5x faster** than NumPy for memory-heavy expressions.\n",
        "\n",
        "---\n",
        "\n",
        "# 🧠 Summary Table: Techniques Compared\n",
        "\n",
        "| Technique | Best For | Speedup Over Python | Notes |\n",
        "|----------|-----------|---------------------|-------|\n",
        "| Loop Unrolling | Small tight loops | ~1.5–2x | Manual, limited benefit |\n",
        "| Numba (@njit) | Numerical loops | ~50–100x | Easy to use, great for arrays |\n",
        "| Numba (parallel) | Multi-core CPU work | ~2x over single-core Numba | Requires no side effects |\n",
        "| Numexpr | Array expressions | ~2–5x over NumPy | Good for large data, string-based expr |\n",
        "\n",
        "---\n",
        "\n",
        "# 🛠 Challenge: Optimize This Computation\n",
        "\n",
        "Given this formula:\n",
        "$$\n",
        "\\text{result}[i,j] = \\frac{\\exp(- (x[i,j] - y[i,j])^2)}{1 + (x[i,j] + y[i,j])^2}\n",
        "$$\n",
        "\n",
        "Compare two implementations:\n",
        "\n",
        "### ✅ Solution 1: Using Numexpr\n",
        "\n",
        "```python\n",
        "def optimized_computation_numexpr(x, y):\n",
        "    return ne.evaluate(\"exp(-(x - y)**2) / (1 + (x + y)**2)\")\n",
        "```\n",
        "\n",
        "### ✅ Solution 2: Using Numba\n",
        "\n",
        "```python\n",
        "@njit\n",
        "def optimized_computation_numba(x, y):\n",
        "    result = np.empty_like(x)\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            diff = x[i, j] - y[i, j]\n",
        "            total = x[i, j] + y[i, j]\n",
        "            result[i, j] = np.exp(-diff**2) / (1 + total**2)\n",
        "    return result\n",
        "```\n",
        "\n",
        "### 📊 Benchmark\n",
        "\n",
        "```python\n",
        "shape = (2000, 2000)\n",
        "x = np.random.rand(*shape)\n",
        "y = np.random.rand(*shape)\n",
        "\n",
        "# Numexpr version\n",
        "start = time.time()\n",
        "result_ne = optimized_computation_numexpr(x, y)\n",
        "ne_time = time.time() - start\n",
        "print(f\"Numexpr time: {ne_time:.4f} sec\")\n",
        "\n",
        "# Numba version\n",
        "start = time.time()\n",
        "result_nb = optimized_computation_numba(x, y)\n",
        "nb_time = time.time() - start\n",
        "print(f\"Numba time: {nb_time:.4f} sec\")\n",
        "print(f\"Speedup: {nb_time / ne_time:.2f}x\")\n",
        "```\n",
        "\n",
        "> 📌 Result:\n",
        "- Numexpr usually wins for large arrays due to threading and expression optimization.\n",
        "- Numba is more flexible and integrates better with logic/conditionals.\n",
        "\n",
        "---\n",
        "\n",
        "# ✅ When to Use What?\n",
        "\n",
        "| Tool | Use Case | Benefit |\n",
        "|------|----------|---------|\n",
        "| Loop Unrolling | Very small loops | Minor gain; rarely worth effort |\n",
        "| Numba | CPU-bound numerical loops | Huge speedups, especially with parallelization |\n",
        "| Numexpr | Large array expressions | Blazing fast for math-heavy formulas |\n",
        "| NumPy | General-purpose vectorization | Already fast, but not always optimal |\n",
        "\n",
        "---\n",
        "\n",
        "# 📌 Takeaways\n",
        "\n",
        "### 🔹 Use Numba for:\n",
        "- Custom loops and computations\n",
        "- Functions with conditionals or custom logic\n",
        "- Needing full control with C-like performance\n",
        "\n",
        "### 🔹 Use Numexpr for:\n",
        "- Heavy array expressions\n",
        "- Memory-bound operations\n",
        "- Where readability and simplicity matter\n",
        "\n",
        "### 🔹 Don’t Use These For:\n",
        "- I/O-bound tasks\n",
        "- String manipulation\n",
        "- One-off scripts where compilation time matters\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vPoDKnawEC-i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGpYk8dnEB6P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def normal_loop(x, y, out):\n",
        "    for i in range(len(x)):\n",
        "        out[i] = x[i] + y[i]\n",
        "\n",
        "def unrolled_loop(x, y, out):\n",
        "    # Process 4 items at a time\n",
        "    for i in range(0, len(x) - 3, 4):\n",
        "        out[i]     = x[i]     + y[i]\n",
        "        out[i + 1] = x[i + 1] + y[i + 1]\n",
        "        out[i + 2] = x[i + 2] + y[i + 2]\n",
        "        out[i + 3] = x[i + 3] + y[i + 3]\n",
        "\n",
        "    # Handle remaining elements\n",
        "    for i in range(len(x) - (len(x) % 4), len(x)):\n",
        "        out[i] = x[i] + y[i]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = 10_000_000\n",
        "a = np.random.rand(size)\n",
        "b = np.random.rand(size)\n",
        "result_normal = np.zeros_like(a)\n",
        "result_unrolled = np.zeros_like(a)\n",
        "\n",
        "# Time normal loop\n",
        "start = time.time()\n",
        "normal_loop(a, b, result_normal)\n",
        "normal_time = time.time() - start\n",
        "print(f\"Normal loop time: {normal_time:.4f} seconds\")\n",
        "\n",
        "# Time unrolled loop\n",
        "start = time.time()\n",
        "unrolled_loop(a, b, result_unrolled)\n",
        "unrolled_time = time.time() - start\n",
        "print(f\"Unrolled loop time: {unrolled_time:.4f} seconds\")\n",
        "print(f\"Speedup: {normal_time / unrolled_time:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPXo-PRhEuF3",
        "outputId": "5cfaa835-aeee-48aa-9c33-40226d29661a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal loop time: 4.8954 seconds\n",
            "Unrolled loop time: 3.9353 seconds\n",
            "Speedup: 1.24x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import jit, njit, prange, set_num_threads\n",
        "\n",
        "@njit  # Fastest mode: nopython=True\n",
        "def numba_loop(x, y):\n",
        "    result = np.empty_like(x)\n",
        "    for i in range(len(x)):\n",
        "        result[i] = x[i] + y[i]\n",
        "    return result\n",
        "\n",
        "@njit(parallel=True)\n",
        "def numba_parallel_loop(x, y):\n",
        "    result = np.empty_like(x)\n",
        "    for i in prange(len(x)):  # Parallelized loop\n",
        "        result[i] = x[i] + y[i]\n",
        "    return result"
      ],
      "metadata": {
        "id": "LqWOR4MKFn9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = 10_000_000\n",
        "a = np.random.rand(size)\n",
        "b = np.random.rand(size)\n",
        "\n",
        "# Baseline: Pure Python loop\n",
        "start = time.time()\n",
        "normal_loop(a, b, result_normal)\n",
        "python_time = time.time() - start\n",
        "print(f\"Python loop time: {python_time:.4f} seconds\")\n",
        "\n",
        "# Numba nopython\n",
        "start = time.time()\n",
        "res_numba = numba_loop(a, b)\n",
        "numba_time = time.time() - start\n",
        "print(f\"Numba loop time: {numba_time:.4f} seconds\")\n",
        "print(f\"Numba speedup: {python_time / numba_time:.2f}x\")\n",
        "\n",
        "# Numba parallel\n",
        "start = time.time()\n",
        "res_numba_par = numba_parallel_loop(a, b)\n",
        "numba_par_time = time.time() - start\n",
        "print(f\"Numba parallel time: {numba_par_time:.4f} seconds\")\n",
        "print(f\"Numba parallel speedup: {python_time / numba_par_time:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpBkCQw_Fti_",
        "outputId": "ec52ddb2-2efb-4afa-c536-c7b84b149428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python loop time: 4.0395 seconds\n",
            "Numba loop time: 1.6296 seconds\n",
            "Numba speedup: 2.48x\n",
            "Numba parallel time: 0.5697 seconds\n",
            "Numba parallel speedup: 7.09x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numexpr as ne\n",
        "import dis as dis\n",
        "\n",
        "def compute_with_numpy(x, y, z):\n",
        "    return np.exp(-(x - y)**2) / (1 + (x + y)**2)\n",
        "\n",
        "def compute_with_numexpr(x, y, z):\n",
        "    return ne.evaluate(\"exp(-(x - y)**2) / (1 + (x + y)**2)\")\n",
        "dis.dis(compute_with_numpy)\n",
        "dis.dis(compute_with_numexpr)"
      ],
      "metadata": {
        "id": "9N5AwtL9GVLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8626e4-bb0a-4d10-837d-b27075938338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  4           0 RESUME                   0\n",
            "\n",
            "  5           2 LOAD_GLOBAL              0 (np)\n",
            "             14 LOAD_METHOD              1 (exp)\n",
            "             36 LOAD_FAST                0 (x)\n",
            "             38 LOAD_FAST                1 (y)\n",
            "             40 BINARY_OP               10 (-)\n",
            "             44 LOAD_CONST               1 (2)\n",
            "             46 BINARY_OP                8 (**)\n",
            "             50 UNARY_NEGATIVE\n",
            "             52 PRECALL                  1\n",
            "             56 CALL                     1\n",
            "             66 LOAD_CONST               2 (1)\n",
            "             68 LOAD_FAST                0 (x)\n",
            "             70 LOAD_FAST                1 (y)\n",
            "             72 BINARY_OP                0 (+)\n",
            "             76 LOAD_CONST               1 (2)\n",
            "             78 BINARY_OP                8 (**)\n",
            "             82 BINARY_OP                0 (+)\n",
            "             86 BINARY_OP               11 (/)\n",
            "             90 RETURN_VALUE\n",
            "  7           0 RESUME                   0\n",
            "\n",
            "  8           2 LOAD_GLOBAL              0 (ne)\n",
            "             14 LOAD_METHOD              1 (evaluate)\n",
            "             36 LOAD_CONST               1 ('exp(-(x - y)**2) / (1 + (x + y)**2)')\n",
            "             38 PRECALL                  1\n",
            "             42 CALL                     1\n",
            "             52 RETURN_VALUE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = 10_000_000\n",
        "x = np.random.rand(size)\n",
        "y = np.random.rand(size)\n",
        "z = np.random.rand(size)\n",
        "\n",
        "# With NumPy\n",
        "start = time.time()\n",
        "result_numpy = compute_with_numpy(x, y, z)\n",
        "numpy_time = time.time() - start\n",
        "print(f\"NumPy time: {numpy_time:.4f} seconds\")\n",
        "\n",
        "# With Numexpr\n",
        "start = time.time()\n",
        "result_numexpr = compute_with_numexpr(x, y, z)\n",
        "numexpr_time = time.time() - start\n",
        "print(f\"Numexpr time: {numexpr_time:.4f} seconds\")\n",
        "print(f\"Numexpr speedup: {numpy_time / numexpr_time:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHS7VcsiGhoh",
        "outputId": "fc549320-6a5e-4873-8679-1f7c674d09ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy time: 0.2521 seconds\n",
            "Numexpr time: 0.1479 seconds\n",
            "Numexpr speedup: 1.70x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔥 Why **Numba** and **Numexpr** Are Faster Than Pure Python\n",
        "\n",
        "When working with numerical data in Python, pure loops or NumPy-only operations can be slow due to Python's dynamic typing, interpreter overhead, and memory inefficiencies.\n",
        "\n",
        "This document explains **why Numba and Numexpr are faster**, how they work under the hood, and when you should use them.\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 Why Is **Numba** Fast?\n",
        "\n",
        "### ✅ Summary:\n",
        "> **Numba compiles Python functions to machine code at runtime**, bypassing the Python interpreter. This results in **C-level performance** for numerical code.\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 How Does It Work?\n",
        "\n",
        "1. **JIT Compilation (Just-In-Time)**  \n",
        "   - When a function is decorated with `@njit` or `@jit`, Numba translates it into optimized machine code using **LLVM**.\n",
        "   - Compilation happens once — subsequent calls reuse the compiled version.\n",
        "\n",
        "2. **Type Inference**\n",
        "   - Numba infers types of variables from actual inputs during the first call.\n",
        "   - No need for explicit type declarations like in C/C++.\n",
        "\n",
        "3. **Vectorization & CPU Instructions**\n",
        "   - Uses modern CPU instructions like **SIMD (Single Instruction Multiple Data)**\n",
        "   - Efficiently maps Python arrays to registers and cache\n",
        "\n",
        "4. **No Python GIL (Global Interpreter Lock) Overhead**\n",
        "   - With `nopython=True`, Numba releases the GIL\n",
        "   - Allows true parallel execution with `prange()` and `parallel=True`\n",
        "\n",
        "5. **Zero Overhead Abstractions**\n",
        "   - Avoids Python object boxing/unboxing\n",
        "   - Directly operates on raw memory buffers\n",
        "\n",
        "---\n",
        "\n",
        "### 🧪 Example: Loop Optimization with Numba\n",
        "\n",
        "```python\n",
        "from numba import njit\n",
        "import numpy as np\n",
        "\n",
        "@njit\n",
        "def sum_loop(arr):\n",
        "    total = 0\n",
        "    for x in arr:\n",
        "        total += x\n",
        "    return total\n",
        "\n",
        "arr = np.random.rand(1_000_000)\n",
        "sum_loop(arr)  # First run compiles\n",
        "sum_loop(arr)  # Subsequent runs are super fast!\n",
        "```\n",
        "\n",
        "| Version | Time (approx.) |\n",
        "|--------|----------------|\n",
        "| Python loop | ~80–100 ms |\n",
        "| NumPy `.sum()` | ~1–2 ms |\n",
        "| Numba JIT | ~0.1 ms |\n",
        "\n",
        "---\n",
        "\n",
        "### ⚙️ Under the Hood: What Makes Numba Fast?\n",
        "\n",
        "| Feature | Benefit |\n",
        "|--------|---------|\n",
        "| Bypasses Python VM | Runs directly as machine code |\n",
        "| Type specialization | Optimized for each input type |\n",
        "| SIMD vectorization | Processes multiple elements per instruction |\n",
        "| Parallel execution | Use `prange` and `parallel=True` |\n",
        "| Memory access | Direct pointer access to NumPy arrays |\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ When to Use Numba?\n",
        "\n",
        "- You're writing custom numerical algorithms (not covered by built-in NumPy)\n",
        "- You have tight loops over large arrays\n",
        "- You want to write Python but get near-C performance\n",
        "- You want to enable multi-core computation with minimal effort\n",
        "\n",
        "---\n",
        "\n",
        "## 🧮 Why Is **Numexpr** Fast?\n",
        "\n",
        "### ✅ Summary:\n",
        "> **Numexpr evaluates array expressions efficiently** using an internal virtual machine that minimizes memory usage and maximizes CPU cache efficiency.\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 How Does It Work?\n",
        "\n",
        "#### Consider this expression:\n",
        "\n",
        "```python\n",
        "result = (a + b * c) / np.sqrt(d)\n",
        "```\n",
        "\n",
        "In standard NumPy:\n",
        "1. Each operation creates a **temporary array** (`b*c`, then `a + temp`, etc.)\n",
        "2. Memory bandwidth becomes the bottleneck\n",
        "\n",
        "With **Numexpr**:\n",
        "```python\n",
        "import numexpr as ne\n",
        "result = ne.evaluate(\"(a + b * c) / sqrt(d)\")\n",
        "```\n",
        "- Parses the string expression into bytecodes\n",
        "- Evaluates element-wise without creating temporary arrays\n",
        "- Keeps everything inside CPU cache\n",
        "- Uses **multi-threaded evaluation**\n",
        "\n",
        "---\n",
        "\n",
        "### 📈 Performance Advantages of Numexpr\n",
        "\n",
        "| Advantage | Description |\n",
        "|----------|-------------|\n",
        "| **Memory Efficiency** | Avoids temporary arrays → reduces memory usage |\n",
        "| **CPU Cache Friendly** | Operates on chunks that fit in L1/L2 cache |\n",
        "| **Multi-threaded** | Scales across CPU cores automatically |\n",
        "| **Vectorized Execution** | Uses SSE2/AVX instructions where available |\n",
        "| **Expression Fusion** | Combines multiple operations into one pass |\n",
        "\n",
        "---\n",
        "\n",
        "### 🧪 Benchmark: NumPy vs Numexpr\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import numexpr as ne\n",
        "import time\n",
        "\n",
        "x = np.random.rand(10_000_000)\n",
        "\n",
        "# NumPy version\n",
        "start = time.time()\n",
        "y_numpy = np.log(np.sin(x)**2 + np.cos(x)**2)\n",
        "numpy_time = time.time() - start\n",
        "\n",
        "# Numexpr version\n",
        "start = time.time()\n",
        "y_ne = ne.evaluate(\"log(sin(x)**2 + cos(x)**2)\")\n",
        "ne_time = time.time() - start\n",
        "\n",
        "print(f\"NumPy: {numpy_time:.4f} sec\")\n",
        "print(f\"Numexpr: {ne_time:.4f} sec\")\n",
        "print(f\"Speedup: {numpy_time / ne_time:.2f}x\")\n",
        "```\n",
        "\n",
        "| Library | Time (approx.) | Speedup |\n",
        "|--------|----------------|---------|\n",
        "| NumPy | ~0.5 s | 1x |\n",
        "| Numexpr | ~0.15 s | ~3.3x |\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ When to Use Numexpr?\n",
        "\n",
        "- You're evaluating **complex array expressions**\n",
        "- Your computations are **memory-bound** (limited by RAM speed)\n",
        "- You're working with **very large arrays**\n",
        "- You want **automatic threading** without writing parallel code\n",
        "\n",
        "---\n",
        "\n",
        "## 🧊 Key Differences Between Numba and Numexpr\n",
        "\n",
        "| Feature | Numba | Numexpr |\n",
        "|--------|-------|---------|\n",
        "| Input | Python functions | String expressions |\n",
        "| Best For | Custom loops, logic, control flow | Array expressions, math-heavy formulas |\n",
        "| Parallelism | Explicit via `prange()` | Automatic |\n",
        "| Compilation | On first run (cached) | Once per expression |\n",
        "| Flexibility | Very high | Limited to supported ops |\n",
        "| Syntax | Native Python | Must write expressions as strings |\n",
        "| Supported Types | Most NumPy dtypes | Floats, ints, bools, strings (limited) |\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 Final Takeaways\n",
        "\n",
        "### ✅ Use **Numba** if:\n",
        "- You're writing **custom numerical loops**\n",
        "- You want full **control over algorithm behavior**\n",
        "- You're doing more than just arithmetic (e.g., conditionals, indexing, state)\n",
        "\n",
        "### ✅ Use **Numexpr** if:\n",
        "- You're doing **math-heavy array expressions**\n",
        "- You want **zero-copy expression evaluation**\n",
        "- You want **simple, fast, automatic multi-threading**\n",
        "\n",
        "### ❌ Don't Use Them If:\n",
        "- You're doing **I/O-bound** tasks (files, sockets, databases)\n",
        "- You're manipulating **strings or objects**\n",
        "- The overhead of compilation outweighs gains (e.g., tiny arrays)\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 Real-World Comparison Table\n",
        "\n",
        "| Task | Pure Python | NumPy | Numba | Numexpr |\n",
        "|------|-------------|--------|--------|----------|\n",
        "| Sum of 1M floats | ~80ms | ~1ms | ~0.1ms | – |\n",
        "| Complex math on 1M floats | ~200ms | ~5ms | ~0.3ms | ~0.15ms |\n",
        "| Vectorized conditional filter | ~150ms | ~3ms | ~0.2ms | ~0.1ms |\n",
        "| Broadcasted matrix op (1000×1000) | – | ~10ms | ~6ms | ~4ms |\n",
        "\n",
        "---\n",
        "\n",
        "## 📦 Bonus: Numba + Numexpr Together?\n",
        "\n",
        "Yes! You can combine both:\n",
        "- Use **Numba** for control flow and custom logic\n",
        "- Use **Numexpr** for complex math expressions inside your function\n",
        "\n",
        "---\n",
        "\n",
        "## 🧾 Summary: Pick the Right Tool\n",
        "\n",
        "| Situation | Recommended Tool |\n",
        "|-----------|------------------|\n",
        "| Small loops, reusable logic | ✅ Numba |\n",
        "| Large array expressions | ✅ Numexpr |\n",
        "| Simple vectorization | ✅ NumPy |\n",
        "| GPU acceleration needed | ✅ CuPy, PyTorch, TensorFlow |\n",
        "| Sparse data | ✅ SciPy.sparse |\n",
        "| Distributed computing | ✅ Dask, Spark |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5m_mt6gDHefx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BV90lyfHtU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}